"""
Test that all the configs in the project are validated, that the validation works
as expected for both json schema and voluptuous types, and that serialization and
deserialization can round trip.
"""

from glob import glob
from typing import Any
import pytest
import yaml
import json
from translations_taskgraph.training_config import (
    Parameters,
    TrainingConfig,
)
from jsonschema import validate
from voluptuous import Schema
import typing

from translations_taskgraph.util.dataclass_helpers import (
    build_json_schema,
    build_voluptuous_schema,
    extract_optional_properties,
)


def load_yaml(path: str):
    with open(path, "r") as file:
        yaml_text = file.read()
        return yaml.safe_load(yaml_text)


@pytest.mark.parametrize(
    "config",
    [
        "taskcluster/configs/config.ci.yml",
        "taskcluster/configs/config.prod.yml",
        "tests/fixtures/config.pytest.enzh.yml",
        "tests/fixtures/config.pytest.yml",
        # If this one fails the config generator needs to be updated.
        #   utils/config_generator.py
        # Re-generate the example config with:
        #   task config-generator -- en pl --name example
        "configs/autogenerated/en-pl-example.yml",
    ],
)
def test_config_parsing(config: str):
    print(f"Reading {config}")
    config_dict = load_yaml(config)
    TrainingConfig.from_dict(config_dict)


@pytest.mark.parametrize(
    "params",
    [
        "taskcluster/test/params/large-lt-en.yml",
        "taskcluster/test/params/small-ru-en.yml",
    ],
)
def test_params_parsing(params: str):
    print(f"Reading {params}")
    params_dict = load_yaml(params)
    config_dict = params_dict["training_config"]
    try:
        TrainingConfig.from_dict(config_dict)
    except Exception as exception:
        print(json.dumps(config_dict, indent=2))
        print(f"Failed to process config from params {params}")
        raise exception


def test_json_schema():
    """
    Validates that the build_json_schema function is working.
    """
    schema: Any = build_json_schema(TrainingConfig)
    instance = load_yaml("taskcluster/configs/config.prod.yml")
    validate(instance=instance, schema=schema)


def test_voluptuous_schema():
    """
    Validates that the build_voluptuous_schema function is working.
    """
    schema = Schema(build_voluptuous_schema(TrainingConfig))
    schema(load_yaml("taskcluster/configs/config.prod.yml"))


def test_kind_yaml_references():
    """
    Ensure `kind.yml` files reference only valid training_config values.
    """

    kind_files = glob("taskcluster/kinds/*/kind.yml")

    def check_values(node: Any, path=""):
        """
        Recursively check the values in the YAML file.
        Arguments:
            node: The node in the YAML dict.
            path: The string representation of the path, e.g.
                  "task-defaults"
                  "task-defaults.attributes"
                  "task-defaults.attributes.cache"
                  "task-defaults.attributes.cache.from-parameters"
                  "task-defaults.attributes.cache.from-parameters.split_chunks"
        """
        # If this is a dict, recurse into all of the values.
        if isinstance(node, dict):
            for key, value in node.items():
                check_values(value, f"{path}.{key}" if path else key)

        # If this is a list, recurse into all of the items in the list.
        elif isinstance(node, list):
            for index, item in enumerate(node):
                check_values(item, f"{path}[{index}]")

        # If this is a string that starts with "training_config.", then assume that
        # this is a lookup into the training config.
        elif isinstance(node, str) and node.startswith("training_config."):
            print(f"  {path}:")
            print(f'    "{node}"')

            # Get the parts.
            # "training_config.taskcluster.split-chunks" -> ["taskcluster", "split-chunks"]
            parts = node[len("training_config.") :].split(".")

            # Start walking the TrainingConfig type to validate it.
            resolved_type = TrainingConfig

            try:
                for part in parts:
                    if typing.get_origin(resolved_type) is dict:
                        # This is typed as a dict, so any "part" can be passed here
                        # as valid, but we shouldn't go further into the type.
                        resolved_type = None
                    else:
                        resolved_type = resolved_type.__annotations__[part.replace("-", "_")]
                        is_optional, extracted_type = extract_optional_properties(resolved_type)
                        if is_optional:
                            resolved_type = extracted_type

            except (AttributeError, ValueError):
                raise ValueError(
                    f"Invalid reference '{node}' in {kind_file}, no matching config value."
                )

    for kind_file in kind_files:
        print(f"Checking {kind_file}")
        check_values(load_yaml(kind_file))


def recursively_remove_none_keys(value: Any):
    if isinstance(value, dict):
        return {
            k: recursively_remove_none_keys(v)
            for k, v in value.items()
            if v is not None
        }  # fmt: skip

    return value


def test_roundtrip_serialization_deserialization():
    params = "taskcluster/test/params/small-ru-en.yml"
    print(f"Reading {params}")
    source_dict = load_yaml(params)
    parameters = Parameters.from_dict(source_dict)
    target_dict = parameters.to_dict()

    assert (
        recursively_remove_none_keys(source_dict) == target_dict
    ), "The serialization can round trip"
