{
  "batch_size": 1024,
  "langs": ["ru_RU", "zh_CN", "ja_JP", "ko_KR"],
  "max_tok_alpha": 2.0,
  "prompt": "wmt24pp",
  "llm": {
    "max_model_len": 1024,
    "tensor_parallel_size": 1
  },
  "decoding": {
    "temperature": 1,
    "min_p": 0.02,
    "n": 32
  }
}
