# The initial configuration was generated using:
# The initial configuration was generated using:
# task config-generator -- en de --name llmaat --fast
#
# The documentation for this config can be found here:
# https://github.com/mozilla/translations/blob/83ea1006be3db4c8aa1f1f17d0ebd60c2e940cd1/taskcluster/configs/config.prod.yml
experiment:
  name: llmaat_pretrain_nllb50_finetune_7M_best_hp2
  src: en
  trg: ru
  best-model: chrf
  use-opuscleaner: 'true'
  opuscleaner-mode: defaults
  bicleaner:
    default-threshold: 0.978
    dataset-thresholds: {}
  monocleaner:
    mono-src:
      default-threshold: 0.0
      dataset-thresholds:
        hplt_mono_v2_0: 0.5
        opus_NLLB_v1: 0.5
    mono-trg:
      default-threshold: 0.0
      dataset-thresholds:
        hplt_mono_v2_0: 0.7
        opus_NLLB_v1: 0.8
  mono-max-sentences-src:
    total: 300_000_000
    per-dataset: 100_000_000
  mono-max-sentences-trg:
    total: 200_000_000
    per-dataset: 100_000_000
  hplt-min-doc-score:
    mono-src: 7.0
    mono-trg: 9.0
  spm-sample-size: 10_000_000
  spm-vocab-size: 32000
  teacher-ensemble: 1
  teacher-mode: two-stage
  teacher-decoder: ctranslate2
  # take 50M of the cleanest examples
  corpus-max-sentences: 50000000
  student-model: base
  # Finetune pretrained student
  pretrained-models: {}
#    distill-student:
#      urls:
#        - "https://firefox-ci-tc.services.mozilla.com/api/queue/v1/task/V1uConDHTn6MHB_78Syrhw/artifacts/public/build"
#      mode: use
#      type: default
#    train-student:
#      urls:
#        - "https://firefox-ci-tc.services.mozilla.com/api/queue/v1/task/fYfw7xpmShWEoxKNsFLrrA/artifacts/public/build"
#      mode: use
#      type: default
  distill: https://storage.googleapis.com/releng-translations-dev/data/llm/en-ru_RU/gemma-3-27b-vllm/finetune10M/diverse_sample.10M
datasets:
  devtest:
  - flores_dev
  - sacrebleu_wmt22
  - sacrebleu_wmt20
  - sacrebleu_wmt18

  test:
  - flores_devtest
  - sacrebleu_wmt23
  - sacrebleu_wmt21
  - sacrebleu_wmt19
  - sacrebleu_wmt17

  train:
#  - opus_NLLB/v1 #
  - url_https://storage.googleapis.com/releng-translations-dev/data/en-ru/nllb.[LANG].zst
  mono-src: []
  mono-trg: []
marian-args:
  decoding-backward:
    beam-size: '12'
    mini-batch-words: '2000'
  decoding-teacher:
    mini-batch-words: '5000'
    maxi-batch: '10000'
  training-backward:
    early-stopping: '5'
  training-teacher:
    early-stopping: '20'
  training-student:
    early-stopping: '15'
  training-student-distilled:
    early-stopping: '20'
    exponential-smoothing: '0.0001'
    valid-freq: '100'
    save-freq: '100'
    disp-freq: '50'
    disp-first: '10'
    learn-rate: '6e-06'
    lr-warmup: '200'
    lr-decay-inv-sqrt: '2000'
#    learn-rate: '0.0001'
#    maxi-batch: '200'
#    mini-batch: '500'
#    lr-warmup: '500'
#    save-freq: '500'
#    valid-freq: '500'
#    disp-freq: '100'
#    sentencepiece-alphas: '0'
#    lr-decay-inv-sqrt: '2000'
  training-student-finetuned:
    early-stopping: '10'
target-stage: evaluate-distilled-student
start-stage: distill-student
#previous_group_ids: ["eZihQcb_REmJN94xCESa8g"]
previous_group_ids: ["DFzySX5hRd2Tn4LN_m5_TQ"]
existing_tasks: {
  "bicleaner-ai-url-gcp_nllb_87d3b0-en-ru": "aokr33xETNSH_TVqmBraJw",
  "alignments-original-en-ru": "XsXCk0ahSGOPseNoo_ha3w",
  "merge-devset-en-ru": "Z7hY8IR1SyG2rsBXJuv4GQ",
  "merge-corpus-en-ru": "e0uorvvoT3KWJ0cy3k2ZoA",
  "train-vocab-en-ru": "NKsp9LbMSNW5VvJiEZWXaw",

#  "distill-student-en-ru": "V1uConDHTn6MHB_78Syrhw",
  "train-student-en-ru": "fYfw7xpmShWEoxKNsFLrrA",

}
wandb-publication: true
taskcluster:
  split-chunks: 20
  worker-classes:
    default: gcp-spot
    alignments-original: gcp-standard
    alignments-backtranslated: gcp-standard
    alignments-student: gcp-standard
    train-student: gcp-standard
    shortlist: gcp-standard
    bicleaner: gcp-standard
