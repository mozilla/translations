# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
---

loader: taskgraph.loader.transform:loader

transforms:
    - translations_taskgraph.transforms.continuation
    - translations_taskgraph.transforms.worker_selection
    - translations_taskgraph.transforms.find_upstreams:by_locales
    - taskgraph.transforms.task_context
    - taskgraph.transforms.run:transforms
    - translations_taskgraph.transforms.cached_tasks:transforms
    - taskgraph.transforms.task:transforms

kind-dependencies:
    - corpus-clean-parallel-bicleaner-ai
    - toolchain

tasks:
    corpus-merge-parallel:
        label: corpus-merge-parallel-{src_locale}-{trg_locale}
        description: >
            Merge all of the cleaned original parallel datasets into a
            corpus.{src_locale}.zst and corpus.{trg_locale}.zst file.

        worker-type: b-cpu-largedisk
        worker:
            docker-image: {"in-tree": "train"}
            max-run-time: 86400
            volumes:
                - /builds/worker/artifacts
            artifacts:
                - name: public/build
                  path: /builds/worker/artifacts
                  type: volume
            env:
                SRC: "{src_locale}"
                TRG: "{trg_locale}"
            # 128 happens when cloning this repository fails
            retry-exit-status: [128]

        # Don't run unless explicitly scheduled
        run-on-tasks-for: []

        attributes:
            src_locale: "{src_locale}"
            trg_locale: "{trg_locale}"
            dataset-category: train
            stage: corpus-merge-parallel
            cache:
                type: corpus-merge-parallel
                from-parameters:
                    max_sentences:
                        - training_config.experiment.corpus-max-sentences
                resources:
                    - pipeline/clean/merge-parallel.py
                    - pipeline/clean/requirements/merge.txt

        task-context:
            from-parameters:
                src_locale: training_config.experiment.src
                trg_locale: training_config.experiment.trg
                max_sentences: training_config.experiment.corpus-max-sentences
            substitution-fields:
                - name
                - label
                - description
                - worker.env
                - dependencies
                - fetches
                - attributes
                - run.command

        upstreams-config:
            upstream-artifacts:
                - "{dataset_sanitized}.{src_locale}.zst"
                - "{dataset_sanitized}.{trg_locale}.zst"
                - "{dataset_sanitized}.scores.zst"
            upstream-task-attributes:
                cleaning-type:
                    by-cleaning-type:
                        corpus-clean-parallel-bicleaner-ai: corpus-clean-parallel-bicleaner-ai
                        # If doing corpus continuation, default to bicleaner-ai.
                        default: bicleaner-ai

        run:
            using: run-task
            command:
                - bash
                - -c
                - >-
                    pip install -r $VCS_PATH/pipeline/clean/requirements/merge.txt &&
                    export PYTHONPATH=$PYTHONPATH:$VCS_PATH &&
                    python3 $VCS_PATH/pipeline/clean/merge-parallel.py
                    --src           {src_locale}
                    --trg           {trg_locale}
                    --artifacts     $TASK_WORKDIR/artifacts
                    --name          corpus
                    --max_lines     {max_sentences}
                    --datasets_glob "$MOZ_FETCHES_DIR/*.zst"
        fetches:
            toolchain:
                - preprocess
