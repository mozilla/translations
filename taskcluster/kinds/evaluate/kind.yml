# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
---

loader: taskgraph.loader.transform:loader

transforms:
    - translations_taskgraph.transforms.continuation
    - translations_taskgraph.transforms.training_continuation:evaluate_stage
    - translations_taskgraph.transforms.from_datasets:per_dataset
    - translations_taskgraph.transforms.worker_selection
    - taskgraph.transforms.task_context
    - translations_taskgraph.transforms.cast_to
    - taskgraph.transforms.chunking
    - taskgraph.transforms.run:transforms
    - translations_taskgraph.transforms.cached_tasks:transforms
    - taskgraph.transforms.task:transforms

kind-dependencies:
    - dataset
    - backtranslations-train-backwards-model
    - train-teacher-model
    - distillation-student-model-train
    - distillation-student-model-finetune
    - toolchain
    - continuation-model

task-defaults:
    attributes:
        cache:
            resources:
                - pipeline/eval/eval.py
    dataset-config:
        category: test
        substitution-fields:
            - description
            - name
            - dependencies
            - fetches
            - worker.env
            - task-context
            - run.command
    task-context:
        substitution-fields:
            - run.command
            - worker.env
        from-parameters:
            best_model: training_config.experiment.best-model
            src_locale: training_config.experiment.src
            trg_locale: training_config.experiment.trg
            split_chunks: training_config.experiment.teacher-ensemble
            wandb_publication: training_config.wandb-publication
            owner: owner
    worker-type: b-gpu
    worker:
        artifacts:
            - name: public/build
              path: artifacts
              type: directory
        max-run-time: 2592000
        env:
            # This is a separate environment variable so tests can override it.
            MARIAN: $MOZ_FETCHES_DIR

            # Weight & Biases trigger
            WANDB_PUBLICATION: "{wandb_publication}"
            WANDB_AUTHOR: "{owner}"

            # Weight & Biases publication token is stored in that secret
            TASKCLUSTER_SECRET: project/translations/level-1/weights-and-biases

        # Taskcluster proxy is required to read secrets
        taskcluster-proxy: true
        # 128 happens when cloning this repository fails
        # 75 - EX_TEMPFAIL, used for when the GPUs aren't available on the machine.
        retry-exit-status: [128, 75]

    # The task needs to be able to read that secret to publish on Weight & Biases
    scopes:
      - secrets:get:project/translations/level-1/weights-and-biases

    # Don't run unless explicitly scheduled
    run-on-tasks-for: []

    run:
        using: run-task
        # The two sed commands here are the unfortunate result of us consuming
        # a marian config that was produced by an earlier step. These configs
        # have hardcoded absolute paths to the models they were trained on,
        # and end invalid when used on a different machine. In theory it is
        # possible to adjust them at generation time to use relative paths,
        # but in practice we have not been able to make this work.
        command:
            - bash
            - -c
            - >-
                export PATH=$PATH:~/.local/bin &&
                export PYTHONPATH=$PYTHONPATH:$VCS_PATH &&
                pip install --upgrade pip &&
                pip install -r $VCS_PATH/pipeline/eval/requirements/eval.txt &&
                pip install $VCS_PATH/tracking &&
                sed -i -e "s,- .*fetches,- $MOZ_FETCHES_DIR," $TASK_WORKDIR/fetches/*.yml &&
                sed -i -e "s,- .*artifacts,- $MOZ_FETCHES_DIR," $TASK_WORKDIR/fetches/*.yml &&
                $VCS_PATH/pipeline/eval/eval.py
                {language_pair}
                --marian_config     "$MOZ_FETCHES_DIR/final.model.npz.best-{best_model}.npz.decoder.yml"
                --models            "$MOZ_FETCHES_DIR/final.model.npz.best-{best_model}.npz"
                --dataset_prefix    "$MOZ_FETCHES_DIR/{dataset_sanitized}"
                --artifacts_prefix  "$TASK_WORKDIR/artifacts/{dataset_sanitized}"
                --marian            "$MARIAN"
                --workspace         "$WORKSPACE"
                --gpus              "$GPUS"
                --model_variant     gpu

tasks:
    backward-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}:
        description: >
            Evaluate the backwards model using a devset. This generates evaluation
            metrics like COMET, bleu, and chrF score.
        attributes:
            stage: evaluate-backwards
            dataset-category: test
            cache:
                type: evaluate-backwards
        task-context:
            substitution-fields:
                - fetches.backtranslations-train-backwards-model
            from-object:
                # Note the target and source locales are flipped for backward models.
                language_pair: >-
                    --src {trg_locale}
                    --trg {src_locale}

        dependencies:
            dataset: dataset-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}
            backtranslations-train-backwards-model: backtranslations-train-backwards-model-{src_locale}-{trg_locale}
        fetches:
            dataset:
                - artifact: "{dataset_sanitized}.{src_locale}.zst"
                  extract: false
                - artifact: "{dataset_sanitized}.{trg_locale}.zst"
                  extract: false
            backtranslations-train-backwards-model:
                - artifact: final.model.npz.best-{best_model}.npz
                  extract: false
                - artifact: final.model.npz.best-{best_model}.npz.decoder.yml
                  extract: false
                - artifact: vocab.{src_locale}.spm
                  extract: false
                - artifact: vocab.{trg_locale}.spm
                  extract: false
            toolchain:
                - marian

    teacher-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}-{this_chunk}:
        description: >
            Evaluate the teacher model using a devset. This generates evaluation
            metrics like COMET, bleu, and chrF score.
        attributes:
            stage: evaluate-teacher
            dataset-category: test
            cache:
                type: evaluate-teacher
        task-context:
            substitution-fields:
                - fetches.train-teacher-model
                - chunk.total-chunks
            from-object:
                language_pair: >-
                    --src {src_locale}
                    --trg {trg_locale}
        cast-to:
            int:
                - chunk.total-chunks

        chunk:
            total-chunks: "{split_chunks}"
            substitution-fields:
                - name
                - description
                - dependencies.train-teacher-model

        dependencies:
            dataset: dataset-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}
            train-teacher-model: train-teacher-model-{src_locale}-{trg_locale}-{this_chunk}
        fetches:
            dataset:
                - artifact: "{dataset_sanitized}.{src_locale}.zst"
                  extract: false
                - artifact: "{dataset_sanitized}.{trg_locale}.zst"
                  extract: false
            train-teacher-model:
                - artifact: final.model.npz.best-{best_model}.npz
                  extract: false
                - artifact: final.model.npz.best-{best_model}.npz.decoder.yml
                  extract: false
                - artifact: vocab.{src_locale}.spm
                  extract: false
                - artifact: vocab.{trg_locale}.spm
                  extract: false
            toolchain:
                - marian

    student-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}:
        description: >
            Evaluate the student model using a devset. This generates evaluation
            metrics like COMET, bleu, and chrF score.
        attributes:
            stage: evaluate-student
            dataset-category: test
            cache:
                type: evaluate-student
        task-context:
            substitution-fields:
                - fetches.distillation-student-model-train
            from-object:
                language_pair: >-
                    --src {src_locale}
                    --trg {trg_locale}

        dependencies:
            dataset: dataset-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}
            distillation-student-model-train: distillation-student-model-train-{src_locale}-{trg_locale}
        fetches:
            dataset:
                - artifact: "{dataset_sanitized}.{src_locale}.zst"
                  extract: false
                - artifact: "{dataset_sanitized}.{trg_locale}.zst"
                  extract: false
            distillation-student-model-train:
                - artifact: final.model.npz.best-{best_model}.npz
                  extract: false
                - artifact: final.model.npz.best-{best_model}.npz.decoder.yml
                  extract: false
                - artifact: vocab.{src_locale}.spm
                  extract: false
                - artifact: vocab.{trg_locale}.spm
                  extract: false
            toolchain:
                - marian

    finetuned-student-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}:
        description: >
            Evaluate the finetuned-student model using a devset. This generates evaluation
            metrics like COMET, bleu, and chrF score.
        attributes:
            stage: evaluate-finetuned-student
            dataset-category: test
            cache:
                type: evaluate-finetuned-student
        task-context:
            substitution-fields:
                - fetches.distillation-student-model-finetune
            from-object:
                language_pair: >-
                    --src {src_locale}
                    --trg {trg_locale}

        dependencies:
            dataset: dataset-{provider}-{dataset_sanitized}-{src_locale}-{trg_locale}
            distillation-student-model-finetune: distillation-student-model-finetune-{src_locale}-{trg_locale}
        fetches:
            dataset:
                - artifact: "{dataset_sanitized}.{src_locale}.zst"
                  extract: false
                - artifact: "{dataset_sanitized}.{trg_locale}.zst"
                  extract: false
            distillation-student-model-finetune:
                - artifact: final.model.npz.best-{best_model}.npz
                  extract: false
                - artifact: final.model.npz.best-{best_model}.npz.decoder.yml
                  extract: false
                - artifact: vocab.{src_locale}.spm
                  extract: false
                - artifact: vocab.{trg_locale}.spm
                  extract: false
            toolchain:
                - marian
