# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
---
loader: taskgraph.loader.transform:loader

transforms:
    - translations_taskgraph.transforms.continuation
    - translations_taskgraph.transforms.worker_selection
    - taskgraph.transforms.task_context
    - translations_taskgraph.transforms.find_upstreams:mono
    - taskgraph.transforms.run:transforms
    - translations_taskgraph.transforms.cached_tasks:transforms
    - taskgraph.transforms.task:transforms

kind-dependencies:
    - corpus-clean-mono
    - corpus-merge-parallel
    - continuation-corpus

task-defaults:
    attributes:
        stage: corpus-merge-mono
        src_locale: "{src_locale}"
        trg_locale: "{trg_locale}"
        cache:
            type: corpus-merge-mono
            resources:
                - pipeline/clean/merge-mono.py
                - pipeline/clean/requirements/merge.txt

    task-context:
        from-parameters:
            src_locale: training_config.experiment.src
            trg_locale: training_config.experiment.trg
        substitution-fields:
            - label
            - description
            - name
            - dependencies
            - fetches
            - upstreams-config.locale
            - attributes
            - run.command

    upstreams-config:
        locale: "{locale}"
        upstream-task-attributes:
            cleaning-type: corpus-clean-mono
        upstream-artifacts:
            - "{dataset_sanitized}.{locale}.zst"

    dependencies:
        corpus-merge-parallel: corpus-merge-parallel-{src_locale}-{trg_locale}

    worker-type: b-cpu-largedisk
    worker:
        chain-of-trust: true
        docker-image: { "in-tree": "train" }
        max-run-time: 86400
        volumes:
            - /builds/worker/artifacts
        artifacts:
            - name: public/build
              path: /builds/worker/artifacts
              type: volume
        env: {}
        # 128 happens when cloning this repository fails
        retry-exit-status: [128]

    # Don't run unless explicitly scheduled
    run-on-tasks-for: []

    run:
        using: run-task
        command:
            - bash
            - -c
            # Arguments are:
            # 1) output
            # 2) max_sentences
            # 3) datasets
            - >-
                pip install -r $VCS_PATH/pipeline/clean/requirements/merge.txt &&
                export PYTHONPATH=$PYTHONPATH:$VCS_PATH &&
                python3 $VCS_PATH/pipeline/clean/merge-mono.py
                --parallel_corpus $MOZ_FETCHES_DIR/corpus/corpus.{locale}.zst
                --output $TASK_WORKDIR/artifacts/mono.{locale}.zst
                --max_sentences {max_sentences}
                --datasets_glob "$MOZ_FETCHES_DIR/*.zst"

    fetches:
        corpus-merge-parallel:
            - artifact: corpus.{locale}.zst
              dest: corpus

tasks:
    src:
        label: corpus-merge-mono-src-{src_locale}
        description: >
            Merge the cleaned monolingual datasets for {src_locale} into a single
            mono.{src_locale}.zst file. This dataset is translated by the teacher model
            in order to synthesize distillation data for training the student model.
        attributes:
            dataset-category: mono-src
            cache:
                from-parameters:
                    max_sentences: training_config.experiment.mono-max-sentences-src.total

        task-context:
            from-parameters:
                locale: training_config.experiment.src
                max_sentences: training_config.experiment.mono-max-sentences-src.total

        upstreams-config:
            upstream-task-attributes:
                dataset-category: mono-src

    trg:
        label: corpus-merge-mono-trg-{trg_locale}
        description: >
            Merge the cleaned monolingual datasets for the target into a single
            mono.{trg_locale}.zst file. This dataset is translated by the backtranslations
            model in order to synthesize backtranslations. The backtranslations are
            used to help train the teacher model.
        attributes:
            dataset-category: mono-trg
            cache:
                from-parameters:
                    max_sentences: training_config.experiment.mono-max-sentences-trg.total

        task-context:
            from-parameters:
                locale: training_config.experiment.trg
                max_sentences: training_config.experiment.mono-max-sentences-trg.total

        upstreams-config:
            upstream-task-attributes:
                dataset-category: mono-trg
